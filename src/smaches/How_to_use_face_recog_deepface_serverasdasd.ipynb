{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from std_msgs.msg import String\n",
    "#from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.remove('/opt/ros/melodic/lib/python2.7/dist-packages')## SI NO TIENEN ROS COMENTEN ESTA LINEA\n",
    "import cv2\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "bridge = CvBridge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rospy\n",
    "import face_recognition\n",
    "from sensor_msgs.msg import Image , LaserScan , PointCloud2\n",
    "rospy.init_node(\"face_recognition\")\n",
    "from hmm_navigation.msg import NavigateActionGoal , NavigateActionResult   ###BETA OPTIONAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from  smach_utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "protoFile = \"/home/takeshi/openpose/models/pose/body_25/pose_deploy.prototxt\"\n",
    "weightsFile = \"/home/takeshi/openpose/models/pose/body_25/pose_iter_584000.caffemodel\"\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rospkg import RosPack\n",
    "\n",
    "rp = RosPack()\n",
    "path_for_faces = rp.get_path('config_files')+'/faces_for_recognition/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=rgbd.get_image()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rospy.sleep(5)\n",
    "data = rospy.wait_for_message(\"/usb_cam/image_raw\",Image,timeout=5) ### FOR DEBUGGING: WHEN USING ROBOT PLEASE CHANGE THIS TOPIC ACCORDINGLY\n",
    "cv2_img = bridge.imgmsg_to_cv2(data)#, \"bgr8\")\n",
    "plt.imshow(cv2_img)\n",
    "image=np.copy(cv2_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=image\n",
    "inHeight = frame.shape[0]\n",
    "inWidth = frame.shape[1]\n",
    "\n",
    "\n",
    "# Prepare the frame to be fed to the network\n",
    "inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "# Set the prepared object as the input blob of the network\n",
    "net.setInput(inpBlob)\n",
    "\n",
    "output = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "frame = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = output.shape[2]\n",
    "W = output.shape[3]\n",
    "threshold=0.5\n",
    "# Empty list to store the detected keypoints\n",
    "points = []\n",
    "for i in range(10):\n",
    "    # confidence map of corresponding body's part.\n",
    "    probMap = output[0, i, :, :]\n",
    "    \n",
    "\n",
    "    # Find global maxima of the probMap.\n",
    "    _, prob,_, point = cv2.minMaxLoc(probMap)\n",
    "    print (point, prob)\n",
    "\n",
    "    # Scale the point to fit on the original image\n",
    "    x = (inWidth * point[0]) / W\n",
    "    y = (inHeight * point[1]) / H\n",
    "\n",
    "    if prob > threshold :\n",
    "        cv2.circle(frame, (int(x), int(y)), 1, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "        cv2.putText(frame, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.51, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "        # Add the point to the list if the probability is greater than the threshold\n",
    "        points.append((int(x), int(y)))\n",
    "    else :\n",
    "        points.append(None)\n",
    "\n",
    "cv2.imshow(\"Output-Keypoints\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "probMap = output[0, i, :, :]\n",
    "probMap = cv2.resize(probMap, (inWidth, inHeight))\n",
    "\n",
    "\n",
    "\n",
    "#plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#plt.imshow(probMap, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=np.where(probMap>0.3)\n",
    "npmask=np.asarray(mask).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = DeepFace.find(image,path_for_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_data=rgbd.get_points()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probmap_to_3d_mean(points_data,probMap, thres_prob=0.3):\n",
    "\n",
    "    mask=np.where(probMap>thres_prob)\n",
    "    npmask=np.asarray(mask).T\n",
    "\n",
    "    npmask.shape\n",
    "    xyz=[]\n",
    "    if len (npmask)>1:\n",
    "        for a in npmask:\n",
    "            ix,iy=a[0],a[1]\n",
    "            aux=(np.asarray((points_data['x'][ix,iy],points_data['y'][ix,iy],points_data['z'][ix,iy])))\n",
    "            #print (aux)\n",
    "            if np.isnan(aux[0]) or np.isnan(aux[1]) or np.isnan(aux[2]):\n",
    "                    'reject point'\n",
    "            else:\n",
    "                xyz.append(aux)\n",
    "\n",
    "    xyz=np.asarray(xyz)\n",
    "    #print (xyz)\n",
    "    cent=xyz.mean(axis=0)\n",
    "    return cent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent=probmap_to_3d_mean(rgbd.get_points(),probMap,0.3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_man.pub_static_tf(pos=cent,point_name='neck', ref= 'head_rgbd_sensor_link',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_2D_3D(points_data, px_y, px_x):\n",
    "    ##px pixels /2D world  P1 3D world\n",
    "    ## rgbd pOINTCLOUD2 numpify\n",
    "    P = np.asarray((points_data[px_y, px_x]['x'], points_data[px_y, px_x]['y'], points_data[px_y, px_x]['z']))\n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probMap\n",
    "npmask= np.where(probMap<0.1,0,probMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from std_msgs.msg import String\n",
    "#from deepface import DeepFace\n",
    "from  smach_utils2 import *\n",
    "data = rospy.wait_for_message(\"/usb_cam/image_raw\",Image,timeout=5) ### FOR DEBUGGING: WHEN USING ROBOT PLEASE CHANGE THIS TOPIC ACCORDINGLY\n",
    "cv2_img = bridge.imgmsg_to_cv2(data)#, \"bgr8\")\n",
    "plt.imshow(cv2_img)\n",
    "image=np.copy(cv2_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_recog.msg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_recog.srv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2_img_bgr= cv2.imread('/home/oscar/Pictures/meandbere.png')\n",
    "cv2_img = cv2.cvtColor(cv2_img_bgr,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(cv2_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LAUNCH SERVICE OR WAIT FOREVER (VALOR MORGULIS)\n",
    "\n",
    "rospy.wait_for_service('recognize_face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LAUNCH SERVICE OR WAIT FOREVER (VALOR MORGULIS)\n",
    "rospy.wait_for_service('new_face')\n",
    "rospy.wait_for_service('analyze_face')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_face = rospy.ServiceProxy('new_face', RecognizeFace)    \n",
    "recognize = rospy.ServiceProxy('recognize_face', RecognizeFace)    \n",
    "analyze = rospy.ServiceProxy('analyze_face', RecognizeFace)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req=RecognizeFaceRequest()\n",
    "\n",
    "strings=Strings()\n",
    "string_msg= String()\n",
    "string_msg.data='any'\n",
    "req.Ids.ids.append(string_msg)\n",
    "\n",
    "img_msg=bridge.cv2_to_imgmsg(cv2_img)\n",
    "\n",
    "req.in_.image_msgs.append(img_msg)\n",
    "res=recognize(req)\n",
    "print(res)\n",
    "name=res.Ids.ids\n",
    "#res = analyze_face(req)\n",
    "#print(res, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "boundRect=np.asarray(res.Angs.data).astype('int')\n",
    "plt.imshow(cv2_img[boundRect[0]:boundRect[2],boundRect[3]:boundRect[1]]                )\n",
    "#plt.imshow(cv2_img[boundRect[4]:boundRect[6],boundRect[7]:boundRect[5]]                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for chars in res.Ids.ids:\n",
    "    results.append(chars.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_face_from_image(image, name[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for chars in res.Ids.ids: # Results from analyze service\n",
    "    results.append(chars.data)\n",
    "results\n",
    "name= 'Jack'\n",
    "pronoun='She'\n",
    "if results[0]=='Man':pronoun='He'\n",
    "    \n",
    "takeshi_line= name+' has arrived A '+results[0]+' I believe '+pronoun +' is  around '+results[-1]+' years old. I would say he is a bit '+results[2]+ ' And I would guess '+pronoun+' is of '+ results[1]+' descent.'\n",
    "print (takeshi_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundRect=np.asarray(res.Angs.data).astype('int')\n",
    "plt.imshow(cv2_img[boundRect[0]:boundRect[1],boundRect[3]:boundRect[2]]                )\n",
    "#plt.imshow(cv2_img[34:201,67:67+167])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name= 'Jack'\n",
    "pronoun='She'\n",
    "if results[0]=='Man':pronoun='He'\n",
    "    \n",
    "takeshi_line= name+' has arrived A '+results[0]+' I believe '+pronoun +' is  around '+results[-1]+' years old. I would say he is a bit '+results[2]+ ' And I would guess he is of '+ results[1]+' descent.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronoun='She'\n",
    "if results[0]=='Man':pronoun='He'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundRect=np.asarray(res.Angs.data).astype('int')\n",
    "plt.imshow(cv2_img[boundRect[0]:boundRect[1],boundRect[3]:boundRect[2]]                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=res.Ids.ids[0].data\n",
    "#talk('I found you, I Think you are .' + name)\n",
    "#print(res.Angs.data)\n",
    "points = rgbd.get_points()\n",
    "boundRect=np.asarray(res.Angs.data).astype('int')                \n",
    "trans = bbox_3d_mean(points, boundRect)\n",
    "print(trans)\n",
    "#############################################################################################\n",
    "##############################################################################################\n",
    "tf_man.pub_static_tf(pos=trans, point_name=name, ref='head_rgbd_sensor_link')\n",
    "\n",
    "rospy.sleep(0.3)\n",
    "tf_man.change_ref_frame_tf(res.Ids.ids[0].data)\n",
    "\n",
    "\n",
    "try:\n",
    "    trans,quat = tf_man.getTF(target_frame=name)\n",
    "except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException):\n",
    "    print ( 'No TF FOUND')\n",
    "omni_base.move_d_to(1.5, name )\n",
    "print (trans)\n",
    "#head.absolute(*trans)\n",
    "\n",
    "talk (name +'... I will lead you to the living room, please follow me')\n",
    "\n",
    "return 'succ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "robot, robotquat = tf_man.getTF('base_link')\n",
    "new_yaw = (tf.transformations.euler_from_quaternion(robotquat)[2]+np.pi) \n",
    "print (new_yaw)\n",
    "        # go to living room an do a 180\n",
    "res = omni_base.move_base(robot[0], robot[1], new_yaw,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_3d_mean(points,boundRect )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_3d_mean(points[boundRect[0]:boundRect[1],boundRect[3]:boundRect[2]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_msg.data='Jack'\n",
    "res=train_new_face(req)  ### FOR TRAINING! IF NAME IS REPETAED WILL CRASH\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type (boundRect), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smach_utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points=rgbd.get_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_3d_mean(points,bbox):\n",
    "    \n",
    "    xyz=[]\n",
    "    bbox[0]\n",
    "    for i in np.arange((int)(bbox[0]),(int)(bbox[0])+(int)(bbox[2])):\n",
    "        for j in np.arange((int)(bbox[1]),(int)(bbox[1])+(int)(bbox[3])):\n",
    "            aa=np.asarray(points[['x','y','z']][i,j])\n",
    "            if np.isnan(np.asarray((aa['x'],aa['y'],aa['z']))).sum() ==0:                   \n",
    "                xyz.append(np.asarray((aa['x'],aa['y'],aa['z'])) )\n",
    "    return np.asarray(xyz).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_3d_mean(points,bbox):\n",
    "    \n",
    "    xyz=[]\n",
    "\n",
    "    for i in np.arange((int)(21.0),(int)(21.0)+(int)(187.0)):\n",
    "        for j in np.arange((int)(178.0),(int)(178.0)+(int)(344.0)):\n",
    "            aa=np.asarray(points[['x','y','z']][i,j])\n",
    "            if np.isnan(np.asarray((aa['x'],aa['y'],aa['z']))).sum() ==0:                   \n",
    "                xyz.append(np.asarray((aa['x'],aa['y'],aa['z'])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z=xyzz.mean(axis=0)\n",
    "x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox=(21,178,187,344)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans=bbox_3d_mean(points,bbox)\n",
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans=xyzz.mean(axis=0)\n",
    "trans[2]+=600\n",
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux=(points[['x','y','z']][-20,410])\n",
    "#np.isnan(aux)\n",
    "aa=np.asarray(aux)\n",
    "np.isnan(np.asarray((aa['x'],aa['y'],aa['z']))).sum()==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21.0, 178.0, 187.0, 344.0\n",
    "for i \n",
    "\n",
    "aux=(points[['x','y','z']][-20,410])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow (points['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=(21.0, 178.0, 187.0, 344.0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    res=DeepFace.extract_faces(image )\n",
    "    print ('face found')\n",
    "    dfs = DeepFace.find(image,path_for_faces)\n",
    "    print('id',dfs[0]['identity'].iloc[0].split('/')[-2])\n",
    "except(ValueError): \n",
    "    print('No Face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DISPLAY IMAGE?#############3\n",
    "#obj=res\n",
    "pt1 = res[0]['facial_area']['x'],res[0]['facial_area']['y'] \n",
    "pt2=  res[0]['facial_area']['x']+res[0]['facial_area']['w'] , res[0]['facial_area']['y']+ res[0]['facial_area']['h']\n",
    "img=cv2.rectangle(image, pt1,pt2, (0, 0, 255), 2)\n",
    "img = cv2.putText(img, dfs[0]['identity'].iloc[0].split('/')[-2], pt1, cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = DeepFace.find(image,path_for_faces)\n",
    "dfs[0]['identity'].iloc[0].split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs = DeepFace.find(image,path_for_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = DeepFace.analyze(image, \n",
    "        actions = ['age', 'gender', 'race', 'emotion']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs[0]['region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs[0]['dominant_gender'],objs[0]['dominant_race'],objs[0]['dominant_emotion'],objs[0]['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for st in (objs[0]['dominant_gender'],objs[0]['dominant_race'],objs[0]['dominant_emotion'],objs[0]['age']):\n",
    "    print (st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs[0]['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_recog.msg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_recog.srv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_face(image, name):\n",
    "    req=RecognizeFaceRequest()\n",
    "    strings=Strings()\n",
    "    string_msg= String()\n",
    "    string_msg.data=name\n",
    "    req.Ids.ids.append(string_msg)\n",
    "\n",
    "    img_msg=bridge.cv2_to_imgmsg(image)\n",
    "    req.in_.image_msgs.append(img_msg)\n",
    "    res=train_new_face(req)\n",
    "    return res.Ids.ids[0].data.split(' ')[0] == 'trained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LAUNCH SERVICE OR WAIT FOREVER (VALOR MORGULIS)\n",
    "\n",
    "rospy.wait_for_service('recognize_face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LAUNCH SERVICE OR WAIT FOREVER (VALOR MORGULIS)\n",
    "rospy.wait_for_service('new_face')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_face = rospy.ServiceProxy('new_face', RecognizeFace)    \n",
    "recognize = rospy.ServiceProxy('recognize_face', RecognizeFace)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req=RecognizeFaceRequest()\n",
    "\n",
    "strings=Strings()\n",
    "string_msg= String()\n",
    "string_msg.data='any'\n",
    "req.Ids.ids.append(string_msg)\n",
    "\n",
    "img_msg=bridge.cv2_to_imgmsg(cv2_img)\n",
    "req.in_.image_msgs.append(img_msg)\n",
    "res=recognize(req)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req=RecognizeFaceRequest()\n",
    "\n",
    "strings=Strings()\n",
    "string_msg= String()\n",
    "string_msg.data='Jack'\n",
    "req.Ids.ids.append(string_msg)\n",
    "\n",
    "img_msg=bridge.cv2_to_imgmsg(image)\n",
    "req.in_.image_msgs.append(img_msg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=train_new_face(req)  ### FOR TRAINING! IF NAME IS REPETAED WILL CRASH\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognition.face_locations(cv2_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################Using Navigation to get to a Distance from this face$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = tf.TransformListener()\n",
    "broadcaster = tf.TransformBroadcaster()\n",
    "pub_goal= rospy.Publisher('/navigate/goal', NavigateActionGoal, queue_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=res.Ds.data[0]\n",
    "D_to_person=0.15\n",
    "pose=np.zeros(3)\n",
    "pose[2]+=d - D_to_person\n",
    "quat=np.zeros(4)\n",
    "quat[-1]=1\n",
    "    \n",
    "\n",
    "broadcaster.sendTransform(pose, quat,rospy.Time.now(), 'face','head_rgbd_sensor_link')\n",
    "for i in range (10):\n",
    "    try:\n",
    "        goal_pose, quat=listener.lookupTransform( 'map','face', rospy.Time(0))\n",
    "        print('yes tf')\n",
    "        break\n",
    "    except:\n",
    "        print  ('No tf')\n",
    "        rospy.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "goal_pose\n",
    "goal= NavigateActionGoal()\n",
    "goal.goal.x=goal_pose[0]\n",
    "goal.goal.y=goal_pose[1]\n",
    "\n",
    "goal.goal.timeout= 10\n",
    "nav_res= NavigateActionResult()\n",
    "pub_goal.publish(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smach_utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res= speech_recog_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2=train_face(image,res.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.Ids.ids[0].data.split(' ')[0] == 'trained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_face(image,res.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from smach_utils2 import *\n",
    "from rospkg import RosPack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = RosPack()\n",
    "path = rp.get_path('config_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rospkg import RosPack\n",
    "\n",
    "rp = RosPack()\n",
    "path_for_faces = rp.get_path('config_files')+'/faces_for_recognition'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_for_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_for_faces = rp.get_path('config_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in os.listdir(path_for_faces):\n",
    "    print (person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(path_for_faces)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni_base.move_base(1,1,np.pi,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot, robotquat = tf_man.getTF('base_link')\n",
    "new_yaw = (tf.transformations.euler_from_quaternion(robotquat)[2]+np.pi)\n",
    "print(new_yaw)\n",
    "# go to living room an do a 180\n",
    "res = omni_base.move_base(robot[0], robot[1], new_yaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import human_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from segmentation.srv import Segmentation, SegmentationResponse \n",
    "from human_detector.srv import Human_detector ,Human_detectorResponse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=Human_detectorResponse()\n",
    "res.x= cent[0]\n",
    "res.y= cent[1]\n",
    "res.z= cent[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=human_detect_server.call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_cam=np.asarray((res.x,res.y,res.z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_man.pub_static_tf(pos=xyz_cam,point_name='face',ref=\"head_rgbd_sensor_rgb_frame\")\n",
    "tf_man.change_ref_frame_tf(point_name='face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni_base.move_d_to(target_link='face')\n",
    "head.to_tf('face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot, robotquat = tf_man.getTF('base_link')\n",
    "new_yaw = (tf.transformations.euler_from_quaternion(robotquat)[2]+np.pi)\n",
    "print(new_yaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = omni_base.move_base(robot[0], robot[1], new_yaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7%(2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = DeepFace.find(image,path_for_faces,enforce_detection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('id',dfs[0]['identity'].iloc[2].split('/')[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('image.npy',image)\n",
    "image=np.load('image.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepFace.extract_faces(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line=analyze_face_from_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if line!=True:\n",
    "    print('yey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_potfields_goal = rospy.Publisher(\"/clicked_point\",PointStamped,queue_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rospy.sleep(5)\n",
    "trans_dict= human_detect_server()\n",
    "trans =[trans_dict.x,trans_dict.y,trans_dict.z]         ##FROM HUMAN FINDER OPEN POSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf_man.pub_static_tf(pos=trans,point_name='goal',ref='head_rgbd_sensor_link')\n",
    "tf_man.change_ref_frame_tf('goal')\n",
    "pt,_=tf_man.getTF('goal')\n",
    "head.to_tf('goal')\n",
    "point= PointStamped()\n",
    "\n",
    "point.point.x=pt[0]\n",
    "point.point.y=pt[1]\n",
    "point.point.z=0.0\n",
    "pub_potfields_goal.publish(point)\n",
    "head.to_tf('goal')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans =[trans_dict.x,trans_dict.y,trans_dict.z]         ##FROM HUMAN FINDER OPEN POSE\n",
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_man.change_ref_frame_tf('goal')\n",
    "pt,_=tf_man.getTF('goal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point= PointStamped()\n",
    "\n",
    "point.point.x=pt[0]\n",
    "point.point.y=pt[1]\n",
    "point.point.z=0.0\n",
    "pub_potfields_goal.publish(point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head.to_tf('goal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['002masterchefcan', '003crackerbox', '004sugarbox', '005tomatosoupcan', '006mustardbottle', '007tunafishcan', '008puddingbox', '009gelatinbox', '010pottedmeatcan', '011banana', '012strawberry', '013apple', '014lemon', '015peach', '016pear', '017orange', '018plum', '019pitcherbase', '021bleachcleanser', '022windexbottle', '024bowl', '025mug', '027skillet', '028skilletlid', '029plate', '030fork', '031spoon', '032knife', '033spatula', '035powerdrill', '036woodblock', '037scissors', '038padlock', '040largemarker', '042adjustablewrench', '043phillipsscrewdriver', '044flatscrewdriver', '048hammer', '050mediumclamp', '051largeclamp', '052extralargeclamp', '053minisoccerball', '054softball', '055baseball', '056tennisball', '057racquetball', '058golfball', '059chain', '061foambrick', '062dice', '063-amarbles', '063-bmarbles', '065-acups', '065-bcups', '065-ccups', '065-dcups', '065-ecups', '065-fcups', '065-gcups', '065-hcups', '065-icups', '065-jcups', '070-acoloredwoodblocks', '070-bcoloredwoodblocks', '071nineholepegtest', '072-atoyairplane', '073-alegoduplo', '073-blegoduplo', '073-clegoduplo', '073-dlegoduplo', '073-elegoduplo', '073-flegoduplo', '073-glegoduplo']\n",
    "def predict_images(images, plt_images=True):\n",
    "    imgs=np.zeros((1,300,300,3))\n",
    "    for image in images :\n",
    "        img=tensorflow.image.resize(image,(300,300))\n",
    "        new=np.expand_dims(img.numpy(),axis=0)\n",
    "        imgs= tensorflow.concat((imgs,new),axis=0)\n",
    "    #Y_pred = np.argmax(model.predict(imgs[1:,:,:,:]),axis=1)\n",
    "    #indices = (-numbers).argsort()[:2]\n",
    "    pred=model.predict(imgs[1:,:,:,:])\n",
    "    \n",
    "    \n",
    "    \n",
    "    top3=np.argsort(pred)[:,-3:]\n",
    "    \n",
    "    Y_pred= top3\n",
    "    titles=[]\n",
    "    for i in range( len(Y_pred)):\n",
    "        titles.append(\" 1. \"+ class_names[Y_pred[i,2]] +'\\n'+ \" 2. \"+ class_names[Y_pred[i,1]] +'\\n'+ \" 3. \"+ class_names[Y_pred[i,0]] )\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    if plt_images:\n",
    "        for i in range(len(images)):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "\n",
    "            plt.imshow(images[i].astype(\"uint8\"))\n",
    "            plt.title(titles[i])\n",
    "            plt.axis(\"off\")\n",
    "        #\n",
    "    \"\"\"\n",
    "        plt.figure(figsize=(10, 10))\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "\n",
    "            plt.imshow(images[i].astype(\"uint8\"))\n",
    "            plt.title(class_names[Y_pred[i]])\n",
    "            plt.axis(\"off\")\"\"\"\n",
    "    return top3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plane_seg_square_imgs(lower=500 ,higher=50000,reg_ly= 30,reg_hy=600,plt_images=True):\n",
    "    image= rgbd.get_h_image()\n",
    "    iimmg= rgbd.get_image()\n",
    "    points_data= rgbd.get_points()\n",
    "    img=np.copy(image)\n",
    "    img3= correct_points()\n",
    "\n",
    "\n",
    "    _,contours, hierarchy = cv2.findContours(img3.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    cents=[]\n",
    "    points=[]\n",
    "    images=[]\n",
    "    for i, contour in enumerate(contours):\n",
    "\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > lower and area < higher :\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "\n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "            image_aux= iimmg[boundRect[1]:boundRect[1]+max(boundRect[2],boundRect[3]),boundRect[0]:boundRect[0]+max(boundRect[2],boundRect[3])]\n",
    "            images.append(image_aux)\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            if (cY > reg_ly and cY < reg_hy  ):\n",
    "\n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                print ('cX,cY',cX,cY)\n",
    "                xyz=[]\n",
    "\n",
    "\n",
    "                for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                        aux=(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "                        if np.isnan(aux[0]) or np.isnan(aux[1]) or np.isnan(aux[2]):\n",
    "                            'reject point'\n",
    "                        else:\n",
    "                            xyz.append(aux)\n",
    "\n",
    "                xyz=np.asarray(xyz)\n",
    "                cent=xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "                print (cent)\n",
    "                points.append(xyz)\n",
    "            else:\n",
    "                print ('cent out of region... rejected')\n",
    "    sub_plt=0\n",
    "    if plt_images:\n",
    "        for image in images:\n",
    "\n",
    "            sub_plt+=1\n",
    "            ax = plt.subplot(5, 5, sub_plt )\n",
    "\n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    cents=np.asarray(cents)\n",
    "    ### returns centroids found and a group of 3d coordinates that conform the centroid\n",
    "    return(cents,np.asarray(points), images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cents,xyz, images=seg_square_imgs(plt_images=True)\n",
    "cents,xyz, images=plane_seg_square_imgs(plt_images=True)\n",
    "\n",
    "static_tf_publish(cents)\n",
    "\n",
    "\n",
    "predict_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res= wait_for_face(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = speech_recog_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.data.split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
